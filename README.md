# ğŸ‘©â€ğŸ’» Pipeline ELT: CenÃ¡rio da Mulher na Tecnologia

![Badge em Desenvolvimento](https://img.shields.io/badge/Status-Concluido-green)
![Python](https://img.shields.io/badge/Python-3.10+-blue)
![dbt](https://img.shields.io/badge/dbt-sqlite-orange)
![Prefect](https://img.shields.io/badge/Prefect-Orchestration-blueviolet)

Este projeto consiste em um pipeline de Engenharia de Dados completo (**E**xtract, **L**oad, **T**ransform) desenvolvido para consolidar e analisar dados sobre a presenÃ§a feminina no mercado de tecnologia global.

O projeto foi criado como parte do **Desafio de Dados do WoMakersCode**, integrando mÃºltiplas fontes de dados heterogÃªneas para responder a perguntas de negÃ³cio atravÃ©s de uma arquitetura moderna e orquestrada.

### ğŸ“Š Dashboard Interativo

Clique na imagem abaixo para explorar os dados detalhadamente:

[![AnÃ¡lise do Perfil da Mulher na Ãrea de Dados](https://public.tableau.com/static/images/Mu/MulheresnaTech/Painel1/1.png)](https://public.tableau.com/views/MulheresnaTech/Painel1)
---

## ğŸ—ï¸ Arquitetura do Projeto

O fluxo de dados segue a arquitetura **ELT** (Extrair, Carregar, Transformar), onde os dados sÃ£o carregados em sua forma bruta no Data Warehouse antes de serem tratados.

```mermaid
graph LR
    A[Fontes de Dados] -->|Python/Pandas| B(ExtraÃ§Ã£o & Carga)
    B -->|Raw Data| C[(SQLite DW)]
    C -->|dbt| D[TransformaÃ§Ã£o & Modelagem]
    D -->|Tabelas Finais| E[AnÃ¡lise]
    subgraph Orquestrador
    F[Prefect] -.-> B
    F -.-> D
    end
````

### O Processo Detalhado:

1.  **IngestÃ£o (Extract & Load):** Scripts Python coletam dados de 4 fontes distintas (CSV, API, Banco SQL e JSON) e os carregam na camada *Raw* (bruta) do Data Warehouse.
2.  **Armazenamento:** UtilizaÃ§Ã£o do **SQLite** como Data Warehouse local (`data_warehouse.db`).
3.  **TransformaÃ§Ã£o (Transform):** O **dbt** (data build tool) consome os dados brutos, aplica limpezas (ex: tratamento de nulos, tipagem de dados, padronizaÃ§Ã£o de nomes) e cria as tabelas dimensÃ£o finais (`marts`).
4.  **OrquestraÃ§Ã£o:** O **Prefect** gerencia o fluxo, garantindo que as transformaÃ§Ãµes sÃ³ ocorram apÃ³s o sucesso da carga, alÃ©m de fornecer logs de execuÃ§Ã£o e retentativas automÃ¡ticas.

-----

## ğŸ› ï¸ Tecnologias Utilizadas

  * **Linguagem:** Python
  * **ManipulaÃ§Ã£o de Dados:** Pandas
  * **Banco de Dados:** SQLite
  * **TransformaÃ§Ã£o:** dbt (adapter dbt-sqlite)
  * **OrquestraÃ§Ã£o:** Prefect
  * **RequisiÃ§Ãµes Web:** Requests
  * **Controle de VersÃ£o:** Git/GitHub

-----

## ğŸ“‚ Fontes de Dados

O projeto integra quatro tipos diferentes de fontes para simular um cenÃ¡rio real de engenharia de dados:

1.  **CSV:** *Kaggle Survey 2022* (Dados filtrados com foco em mulheres na Ã¡rea de dados).
2.  **API:** *REST Countries* (Dados geogrÃ¡ficos para enriquecimento).
3.  **SQL:** *Banco Bootcamp* (SimulaÃ§Ã£o de um banco de dados transacional de participantes).
4.  **JSON:** *Habilidades* (Arquivo semiestruturado mapeando categorias de ferramentas).

-----

## ğŸš€ Como Executar o Projeto

Este projeto foi desenhado para rodar preferencialmente no **Google Colab**, pois o cÃ³digo cria a estrutura de arquivos do dbt dinamicamente.

### PrÃ©-requisitos

  * Uma conta Google.
  * Acesso ao Google Colab.

### Passo a Passo

1.  **Clone ou Baixe o Notebook:**
    Baixe o arquivo `.ipynb` deste repositÃ³rio e faÃ§a o upload para o seu Google Drive ou abra diretamente no Colab.

2.  **InstalaÃ§Ã£o das DependÃªncias:**
    A primeira cÃ©lula do notebook instala tudo o que Ã© necessÃ¡rio:

    ```bash
    !pip install pandas prefect dbt-sqlite requests
    ```

3.  **ExecuÃ§Ã£o do Pipeline:**
    Execute as cÃ©lulas sequencialmente. O notebook estÃ¡ estruturado da seguinte forma:

      * **ConfiguraÃ§Ã£o:** Instala libs e cria o banco de dados.
      * **FunÃ§Ãµes de ExtraÃ§Ã£o:** Define como ler cada fonte.
      * **ConfiguraÃ§Ã£o do dbt:** Cria o projeto dbt (`dbt init`) e os arquivos SQL (`models`) dinamicamente usando comandos `%%writefile`.
      * **OrquestraÃ§Ã£o:** A Ãºltima cÃ©lula contÃ©m o fluxo do **Prefect** que roda todo o processo de ponta a ponta.

### Estrutura de DiretÃ³rios (Gerada Automaticamente)

ApÃ³s a execuÃ§Ã£o, o ambiente terÃ¡ a seguinte estrutura:

```text
/content/
â”œâ”€â”€ PipelinesMulheresNaTech/       # Projeto dbt
    â”œâ”€â”€ dbt_project.yml
    â”œâ”€â”€ models/
    â”‚   â”œâ”€â”€ staging/               # Limpeza de dados (Views)
    â”‚   â””â”€â”€ marts/                 # Tabelas Finais
    â””â”€â”€ data_warehouse.db              # Banco de dados central
    â”œâ”€â”€ bootcampBI.db                  # Fonte simulada
    â”œâ”€â”€ kaggle_survey_2022.csv         # Fonte CSV
    â”œâ”€â”€ habilidades_categorias.json    # Fonte JSON
    â””â”€â”€ pipeline.log                   # Logs de execuÃ§Ã£o
```

-----

## ğŸ“Š Perguntas de NegÃ³cio Respondidas

ApÃ³s a execuÃ§Ã£o do pipeline, a tabela final `dim_desenvolvedoras` permite responder:

  * Quantas mulheres participaram da pesquisa do Kaggle em 2022?
  * Qual a mÃ©dia salarial (em dÃ³lares) por nÃ­vel de experiÃªncia?
  * Quais sÃ£o as ferramentas de BI mais utilizadas?
  * Qual a distribuiÃ§Ã£o geogrÃ¡fica das participantes?

-----

## âœ’ï¸ Autores

  * **Letycia Locha** - *EdiÃ§Ã£o e ComplementaÃ§Ã£o do Pipeline*
  * **WoMakersCode** - *Proposta do Desafio*

-----

*Este projeto Ã© para fins educacionais e demonstraÃ§Ã£o de competÃªncias em Engenharia de Dados.*

```
```
